version: "2"
services:
  namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
  datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./config      
  resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
  nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config
  kafka:
    image: 'bitnami/kafka:latest'
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
  kafka-monitor:
    image: provectuslabs/kafka-ui
    ports:
      - 8080:8080
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      SPRING_CONFIG_ADDITIONAL-LOCATION: /kui.yaml
      DYNAMIC_CONFIG_ENABLED: "true"
    volumes:
      - ./kui.yaml:/kui.yaml
  dev-ingestion-arbiter:
    image: deadcoder11u2/ubuntu:fat
    command: ["bash","/entrypoint.sh"]
    volumes:
      - ../examples/stream.py:/stream.py
      - ../examples/stream.csv:/stream.csv
      - ./entrypoint.sh:/entrypoint.sh
  spark:
    image: docker.io/deadcoder11u2/datahive:spark
    build:
      context: ../app/spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '8085:8080'
    volumes:
      - ../app/spark:/opt/datahive/spark
      - ./m2:/root/.m2
      - ../app/proto:/opt/datahive/proto
  minio:
    image: quay.io/minio/minio
    ports:
      - 9000:9000
      - 9001:9001
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - ./data:/data
  elastic:
    image: elasticsearch:7.17.11
    environment:
      - "discovery.type=single-node"
      - "ES_JAVA_OPTS=-Xmx3g"
    ports:
      - 9200:9200
  kibana:
    image: kibana:7.17.11
    environment:
      - "ELASTICSEARCH_HOSTS=http://elastic:9200"
    ports:
      - 5601:5601
  dev-ingestion:
    image: docker.io/deadcoder11u2/datahive:ingestion
    build:
      context: ../app/ingestion
    ports:
      - 8081:8080
    volumes:
      - ./m2:/root/.m2
